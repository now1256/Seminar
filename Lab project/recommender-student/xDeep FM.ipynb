{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9415dfb5-e30b-4aea-ba79-647ccb4d3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49950500-5d4c-4afd-a6c3-57bee78618fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\db\\AppData\\Local\\Temp\\ipykernel_36440\\1374857115.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train= pd.read_csv(DATASET_DIR+ \"/NCF 졸업생 데이터 (1부).csv\", sep='|')[['sex','ccd','bzc_cd','grup_cd']]\n",
      "C:\\Users\\db\\AppData\\Local\\Temp\\ipykernel_36440\\1374857115.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv(DATASET_DIR+ \"/NCF 졸업생 데이터 (2부).csv\", sep='|')[['sex','ccd','bzc_cd','grup_cd']]\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"C:/Users/db/Desktop/기업-수강ncf/NCF 졸업생 데이터\"\n",
    "train= pd.read_csv(DATASET_DIR+ \"/NCF 졸업생 데이터 (1부).csv\", sep='|')[['sex','ccd','bzc_cd','grup_cd']]\n",
    "test = pd.read_csv(DATASET_DIR+ \"/NCF 졸업생 데이터 (2부).csv\", sep='|')[['sex','ccd','bzc_cd','grup_cd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f61f889-9b16-4b15-82f0-dadf881ca545",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list = np.concatenate([train.values, test.values])\n",
    "n_rating_list = []\n",
    "for a in rating_list:\n",
    "    sex,ccd,bzc_cd,grup_cd = a\n",
    "    n_rating_list.append([sex,ccd,bzc_cd,grup_cd])\n",
    "rating_list = np.array(n_rating_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096bb848-a925-484c-a4b5-4390ce778861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_ccd:314 num_bzc:925 num_item:16695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 모든 유저와 모든 item을 담음\n",
    "unq_ccd, unq_bzccd,unq_grup_cd = [np.unique(rating_list[:, n+1]) for n in range(3)]\n",
    "# user와 item의 개수 넣음\n",
    "num_ccd, num_bzc, num_grup = len(unq_ccd), len(unq_bzccd),len(unq_grup_cd)\n",
    "print('num_ccd:{} num_bzc:{} num_item:{}'.format(num_ccd, num_bzc, num_grup))\n",
    "train_list = np.array(train)\n",
    "test_list = np.array(test)\n",
    "ccd2idx, bzcidx ,grupidx = {}, {},{}\n",
    "for i, j in enumerate(unq_ccd):\n",
    "     ccd2idx[j] = i\n",
    "for i, j in enumerate(unq_bzccd):\n",
    "     bzcidx[j] = i\n",
    "for i, j in enumerate(unq_grup_cd):\n",
    "     grupidx[j] = i    \n",
    "train_list = [[int(li[0])-1,ccd2idx[str(li[1])], bzcidx[str(li[2])],grupidx[str(li[3])]] for li in rating_list]\n",
    "# x_train, x_test = train_test_split(train_list, test_size=0.3, shuffle=True, random_state=34)\n",
    "train_list = pd.DataFrame(train_list, columns = ['sex', 'ccd','bzc','item'])\n",
    "x_train, x_test = train_test_split(train_list, test_size=0.3, shuffle=True, stratify =train_list[['sex', 'ccd','bzc']], random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d65ff1-661d-48e2-ad4d-0d5f5ebf3dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DfData(torch.utils.data.Dataset):\n",
    "    def __init__(self,features,num_sex,num_ccd,num_bzc,num_grup,num_ng=0,train_mat=None,is_training=None):\n",
    "        super(DfData,self).__init__()\n",
    "        # self.features_ps = torch.Tensor(features).int()\n",
    "        self.features_ps = features\n",
    "        self.num_sex = num_sex\n",
    "        self.num_bzc = num_bzc\n",
    "        self.num_ccd = num_ccd\n",
    "        self.num_grup = num_grup\n",
    "        self.num_ng = num_ng\n",
    "        self.labels = [0] * len(features)\n",
    "        self.train_mat = train_mat\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # negative sampling \n",
    "    def set_ng_sample(self):\n",
    "        assert self.is_training, \"no need to sampling when testing\"\n",
    "         \n",
    "        self.features_ng = []\n",
    "        for x in self.features_ps:\n",
    "            # sex\n",
    "            for _ in range(self.num_ng):\n",
    "                s = np.random.randint(self.num_sex)\n",
    "                u = np.random.randint(self.num_ccd)\n",
    "                q = np.random.randint(self.num_bzc)\n",
    "                j = np.random.randint(self.num_grup)\n",
    "                # train set에 있는 경우 다시 뽑기\n",
    "                self.features_ng.append([s,u,q,j])\n",
    "\n",
    "        labels_ps = [1] * len(self.features_ps)\n",
    "        labels_ng = [0] * len(self.features_ng)\n",
    "        \n",
    "        self.features_fill = torch.Tensor(self.features_ps + self.features_ng).to(torch.int64)\n",
    "        self.labels_fill= torch.Tensor(labels_ps + labels_ng)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_ng+1) * len(self.labels)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        features = self.features_fill if self.is_training else torch.Tensor(self.features_ps).to(torch.int64)\n",
    "        labels = self.labels_fill if self.is_training else torch.Tensor(self.labels)\n",
    "        \n",
    "        user = features[idx]\n",
    "        label = labels[idx]\n",
    "        return user, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe497459-ec98-42f5-95b1-b6433a2112c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sex = 2\n",
    "x_train = x_train.values.tolist()\n",
    "x_test = x_test.values.tolist()\n",
    "train_dataset = DfData(x_train, num_sex,num_ccd,num_bzc, num_grup, num_ng=1, is_training=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size = 128, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d53fbc-ff77-4f35-a8c9-59c52b083e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,    44,   155,   699],\n",
      "        [    0,    45,   588,  4019],\n",
      "        [    0,   153,   801,  3285],\n",
      "        [    0,   165,   490, 13138],\n",
      "        [    1,   180,   165, 12919],\n",
      "        [    0,    66,   814,  7268],\n",
      "        [    0,    28,   284,  1378],\n",
      "        [    0,    82,   648,    10],\n",
      "        [    1,   150,   374,  6667],\n",
      "        [    0,   198,   315,   328],\n",
      "        [    0,    36,   755,  1236],\n",
      "        [    1,   280,   712, 15219],\n",
      "        [    1,   220,   852,   308],\n",
      "        [    1,    14,   690, 16053],\n",
      "        [    0,   228,   572,  1236],\n",
      "        [    0,    57,    25,  5510],\n",
      "        [    1,     1,   613,   338],\n",
      "        [    0,   125,    13,  1131],\n",
      "        [    0,    61,   389,  4289],\n",
      "        [    0,   157,    43,  2119],\n",
      "        [    0,   106,   481,    26],\n",
      "        [    1,    51,   527,  5167],\n",
      "        [    0,   273,   770,  3695],\n",
      "        [    1,     9,   137,  8584],\n",
      "        [    0,   213,   731,  1252],\n",
      "        [    0,     9,   613,   434],\n",
      "        [    0,    92,   464,  7836],\n",
      "        [    1,   267,   908, 13991],\n",
      "        [    1,   222,   879,  6124],\n",
      "        [    0,    84,   649,  1998],\n",
      "        [    1,     8,    70, 11290],\n",
      "        [    1,    35,   650, 13664],\n",
      "        [    0,   133,   679, 10600],\n",
      "        [    0,   206,   652,   602],\n",
      "        [    1,   217,   888, 10318],\n",
      "        [    0,    89,   753,   307],\n",
      "        [    0,     0,   153, 14082],\n",
      "        [    0,   168,   444, 14279],\n",
      "        [    1,    46,   364, 15747],\n",
      "        [    1,    69,    11, 14587],\n",
      "        [    1,   156,   799, 11224],\n",
      "        [    1,   156,   579,   520],\n",
      "        [    1,   310,   411,  9949],\n",
      "        [    0,   190,   489,  3941],\n",
      "        [    1,    24,   801,  9008],\n",
      "        [    0,     7,   814,  1088],\n",
      "        [    1,   140,   889, 12545],\n",
      "        [    1,    76,   138, 14917],\n",
      "        [    1,   279,   869,  6540],\n",
      "        [    1,     6,   684,   316],\n",
      "        [    0,   263,   565,  1413],\n",
      "        [    0,    90,   792,   306],\n",
      "        [    0,    82,   818,    80],\n",
      "        [    0,   221,     7, 11797],\n",
      "        [    0,   197,   814,  5168],\n",
      "        [    0,   183,   153, 13269],\n",
      "        [    1,   139,   852, 12138],\n",
      "        [    1,   184,   687,  6154],\n",
      "        [    0,    80,   602,  6915],\n",
      "        [    0,   211,   776, 12778],\n",
      "        [    0,    54,   649,  1414],\n",
      "        [    1,   137,   573,  7379],\n",
      "        [    1,   308,   369, 16362],\n",
      "        [    1,    37,   873, 13892],\n",
      "        [    1,   245,   296, 13383],\n",
      "        [    0,    20,   521,  6842],\n",
      "        [    0,    27,   149,   343],\n",
      "        [    0,    20,   753,    33],\n",
      "        [    0,   121,   324,   259],\n",
      "        [    0,    90,    40,   567],\n",
      "        [    0,    81,   244,  1854],\n",
      "        [    0,   229,   225, 14705],\n",
      "        [    1,    89,   341,  3183],\n",
      "        [    1,   200,   733, 12793],\n",
      "        [    1,    40,   487,  2183],\n",
      "        [    1,    84,   247,  6355],\n",
      "        [    1,   177,   432,  6484],\n",
      "        [    1,   212,   710,  8939],\n",
      "        [    0,   150,   739,   969],\n",
      "        [    0,    89,   869,   256],\n",
      "        [    1,    63,   851,  3734],\n",
      "        [    1,   184,   727,  2461],\n",
      "        [    0,    46,   644, 11733],\n",
      "        [    0,   186,   477, 13172],\n",
      "        [    0,   122,   666,   335],\n",
      "        [    1,   193,   378,  5627],\n",
      "        [    0,   149,   679,  3587],\n",
      "        [    1,   141,   799,  1693],\n",
      "        [    1,   143,    94, 11960],\n",
      "        [    1,    48,   416,   444],\n",
      "        [    1,     1,   776, 15657],\n",
      "        [    0,   270,    13, 16217],\n",
      "        [    0,   142,   799,  3536],\n",
      "        [    0,    84,   814,  2009],\n",
      "        [    0,    77,   721, 14365],\n",
      "        [    1,    18,    89,  8740],\n",
      "        [    1,     0,   855,  2193],\n",
      "        [    1,   271,   615,  5815],\n",
      "        [    1,   139,   852, 12146],\n",
      "        [    0,    47,   756,  8958],\n",
      "        [    0,   276,   795,   221],\n",
      "        [    0,   292,   137,  7209],\n",
      "        [    0,   108,   791,  9276],\n",
      "        [    1,   176,   637,  6629],\n",
      "        [    1,   135,   727, 14687],\n",
      "        [    0,   297,   131,  6085],\n",
      "        [    1,   179,   145,  5163],\n",
      "        [    0,    66,   804, 11933],\n",
      "        [    0,    80,   668, 13442],\n",
      "        [    0,    98,   814,   423],\n",
      "        [    0,   273,   599, 14110],\n",
      "        [    0,    84,   418,     4],\n",
      "        [    1,   266,   279,  1259],\n",
      "        [    1,    20,   753,  6822],\n",
      "        [    1,   134,   825, 10768],\n",
      "        [    0,    44,   165,  8883],\n",
      "        [    1,   134,   271, 14476],\n",
      "        [    1,   105,   163,   805],\n",
      "        [    1,    50,   228,  8823],\n",
      "        [    0,    63,   515, 13543],\n",
      "        [    0,   265,    14,  4513],\n",
      "        [    1,    82,   559, 13359],\n",
      "        [    1,   141,   253,   338],\n",
      "        [    1,   165,   153, 13920],\n",
      "        [    1,    50,   218,  1443],\n",
      "        [    1,   187,   920, 12083],\n",
      "        [    0,   153,   230,  3354],\n",
      "        [    0,   300,   100,  3875]])\n",
      "tensor([1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1.])\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_ng_sample()\n",
    "for a,b in train_loader:\n",
    "    print(a)\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c1a4ec-eec5-409b-83e9-ce2caa6735f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesEmbedding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int64())\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2715e0-2427-46db-828c-9f622a823172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesLinear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, field_dims, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int64())\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2273d3-b7b9-403e-ab3f-4c049e8d1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in embed_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, embed_dim)``\n",
    "        \"\"\"\n",
    "        return self.mlp(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c30847c1-2fd6-4abf-9c50-04c8c054c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, reduce_sum=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78df558-653f-4c78-82a2-2ff94d6dc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_dim, cross_layers):\n",
    "        super(CrossNetwork, self).__init__()\n",
    "        self.cross_layers = cross_layers\n",
    "        self.cross_weights = torch.nn.ModuleList(\n",
    "            [torch.nn.Linear(input_dim, 1) for _ in range(cross_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_0 = x\n",
    "        x_cross = x\n",
    "        for i in range(self.cross_layers):\n",
    "            x_cross = x_0 * x_cross @ self.cross_weights[i].weight.t() + self.cross_weights[i].bias\n",
    "        return x_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "485fc708-d33d-4b58-90f7-e635144a4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class DeepFactorizationMachineModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A pytorch implementation of DeepFM.\n",
    "\n",
    "    Reference:\n",
    "        H Guo, et al. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, 2017.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim, mlp_dims,cross_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.linear = FeaturesLinear(field_dims)\n",
    "        self.fm = FactorizationMachine(reduce_sum=True)\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n",
    "        self.cross = CrossNetwork(self.embed_output_dim, cross_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        embed_x = self.embedding(x)\n",
    "        x = self.linear(x) + self.fm(embed_x) + self.mlp(embed_x.view(-1, self.embed_output_dim)) + self.cross(embed_x.view(-1, self.embed_output_dim))\n",
    "        # return torch.sigmoid(x.squeeze(1))\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc79fc7-5774-49bd-ad68-3ea1a184b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721bcc4f-d660-4e44-8c51-dc1b3621508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_dims = [sex, num_ccd,num_bzc,num_grup]\n",
    "embed_dim= 50\n",
    "cross_layers = 1\n",
    "mlp_dims = [50, 50] \n",
    "dropout= 0.2\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d69787-11f3-4c7d-957c-c508d0effd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFactorizationMachineModel(\n",
       "  (linear): FeaturesLinear(\n",
       "    (fc): Embedding(17936, 1)\n",
       "  )\n",
       "  (fm): FactorizationMachine()\n",
       "  (embedding): FeaturesEmbedding(\n",
       "    (embedding): Embedding(17936, 50)\n",
       "  )\n",
       "  (mlp): MultiLayerPerceptron(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=200, out_features=50, bias=True)\n",
       "      (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.2, inplace=False)\n",
       "      (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cross): CrossNetwork(\n",
       "    (cross_weights): ModuleList(\n",
       "      (0): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = DeepFactorizationMachineModel(field_dims, embed_dim , mlp_dims, cross_layers, dropout)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c91b003-c3fb-415b-a4c9-326db5d2da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "epochs = 50\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfd55de-1aae-4861-b224-9ff4269f0e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.140909985\n",
      "Epoch: 0002 cost = 0.039061595\n",
      "Epoch: 0003 cost = 0.026132993\n",
      "Epoch: 0004 cost = 0.022084229\n",
      "Epoch: 0005 cost = 0.021067077\n",
      "Epoch: 0006 cost = 0.019773917\n",
      "Epoch: 0007 cost = 0.019906111\n",
      "Epoch: 0008 cost = 0.019099928\n",
      "Epoch: 0009 cost = 0.018561093\n",
      "Epoch: 0010 cost = 0.018969154\n",
      "Epoch: 0011 cost = 0.018377854\n",
      "Epoch: 0012 cost = 0.018061195\n",
      "Epoch: 0013 cost = 0.017917056\n",
      "Epoch: 0014 cost = 0.019029960\n",
      "Epoch: 0015 cost = 0.018591674\n",
      "Epoch: 0016 cost = 0.018066378\n",
      "Epoch: 0017 cost = 0.018924104\n",
      "Epoch: 0018 cost = 0.018629055\n",
      "Epoch: 0019 cost = 0.017441109\n",
      "Epoch: 0020 cost = 0.018406250\n",
      "Epoch: 0021 cost = 0.017888952\n",
      "Epoch: 0022 cost = 0.017600726\n",
      "Epoch: 0023 cost = 0.018199245\n",
      "Epoch: 0024 cost = 0.018267829\n",
      "Epoch: 0025 cost = 0.017810838\n",
      "Epoch: 0026 cost = 0.018111806\n",
      "Epoch: 0027 cost = 0.018131357\n",
      "Epoch: 0028 cost = 0.017948495\n",
      "Epoch: 0029 cost = 0.018352468\n",
      "Epoch: 0030 cost = 0.018370332\n",
      "Epoch: 0031 cost = 0.019007785\n",
      "Epoch: 0032 cost = 0.018264351\n",
      "Epoch: 0033 cost = 0.018428624\n",
      "Epoch: 0034 cost = 0.018209333\n",
      "Epoch: 0035 cost = 0.018217213\n",
      "Epoch: 0036 cost = 0.018431755\n",
      "Epoch: 0037 cost = 0.018258335\n",
      "Epoch: 0038 cost = 0.018860340\n",
      "Epoch: 0039 cost = 0.018046997\n",
      "Epoch: 0040 cost = 0.017935161\n",
      "Epoch: 0041 cost = 0.018351603\n",
      "Epoch: 0042 cost = 0.018290184\n",
      "Epoch: 0043 cost = 0.017958675\n",
      "Epoch: 0044 cost = 0.017991727\n",
      "Epoch: 0045 cost = 0.019191390\n",
      "Epoch: 0046 cost = 0.018546740\n",
      "Epoch: 0047 cost = 0.018095488\n",
      "Epoch: 0048 cost = 0.019214032\n",
      "Epoch: 0049 cost = 0.018606313\n",
      "Epoch: 0050 cost = 0.018774290\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):   \n",
    "    avg_cost = 0\n",
    "    train_loader.dataset.set_ng_sample()\n",
    "    for user, label in train_loader:\n",
    "        user = user.to(torch.int64).to(device)\n",
    "        label = label.to('cuda:0')\n",
    "        net.zero_grad()\n",
    "        pred = net(user)\n",
    "        loss = loss_function(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += loss / len(train_loader)\n",
    "    net.eval()\n",
    "    # HR = metrics(net, test_loader, 10)    \n",
    "    # print(np.mean(HR))\n",
    "    print('Epoch:', '%04d' % (ep + 1), 'cost =', '{:.9f}'.format(avg_cost)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4fa8af-327b-4f28-8c77-8316a8447a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net,\"C:/Users/db/Desktop/deep_fm/Deep_fm.pth\")\n",
    "model_path = \"C:/Users/db/Desktop/deep_fm/xDeep_fm.pth\"\n",
    "net = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8f7c88c-ee00-4b96-b72b-4e89eb64c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net,\"C:/Users/db/Desktop/deep_fm/xDeep_fm.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d337b0f-cf81-4db2-ab0e-7bc4c2c32eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 \n",
    "# 1 . test셋에 있는 sex , ccd, grup_cd를 돌리고 -> 원래라면 실제 학습에 들어간 grup은 빼고/ 왜나면 기업은 이전에 들은것이 무엇인지 모름 /테스트 \n",
    "# -> 사실상 hit - ndcg로 가는게 맞지 않나? hit - ndcg만 해가자 \n",
    "# 2 . 그리고 top-k 개로 뽑아서 실제 test-set에 있는 거랑 비교 \n",
    "\n",
    "# ncf \n",
    "#1. 각 기업에 대한 과목의 예측을 뽑고 top-k개로 그 예측이 test셋에 있는지 확인  ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "931d095e-85a6-44cf-83c4-d371d63de80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, -10,  -5,  -4,  -1,   3,   0, -24,   7,   0,   3,  -7, -29,  -2,\n",
       "        -27,  -8,   0, -16,  -5, -17, -21, -20,  -4,  -7,  -1, -12,  -1, -22,\n",
       "        -21,  -1, -12,  -7,  -1,  -2,  -8,  -6,  -5,  -9,  -2,   0,  -4,  -8,\n",
       "        -13,  -4, -20, -16, -37,  -4,  -9,  -2,  -3,  -1,  -3,   7,  -5, -13,\n",
       "         -6, -22, -35, -29, -38, -19, -26, -13,  -1, -17, -12, -11, -13, -15,\n",
       "        -27, -28, -16, -16, -19, -25, -30, -24, -33, -20, -11, -25,  -8, -13,\n",
       "        -20, -27, -22, -17, -16, -51, -46, -46, -13, -25, -23, -25, -32, -32,\n",
       "        -28, -26], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = 'cuda:0'\n",
    "topn=10\n",
    "user_sex=1\n",
    "user_id = 8\n",
    "user_ccd = 224\n",
    "a = []\n",
    "for i in range(num_grup):\n",
    "    item = i\n",
    "    a.append([user_sex,user_ccd,user_id,item])\n",
    "a = torch.tensor(a).to(device)\n",
    "output = net(a)\n",
    "output.to(torch.int)[0:100]\n",
    "# with torch.no_grad():  \n",
    "#     values , sorted_indices = torch.sort(net(torch.tensor(a).to(device)), descending=True)\n",
    "    \n",
    "#     # 순위를 얻기 위해 정렬된 순서의 순서를 다시 정렬합니다.\n",
    "#     rank = torch.argsort(sorted_indices)\n",
    "#     top_10_rank = rank[:topn]\n",
    "#     top_10_values = values[:topn]\n",
    "    \n",
    "#     # 결과 출력\n",
    "#     print(\"상위 {}개의 순위 (rank):\".format(topn), top_10_rank)\n",
    "#     print(\"상위 {}개의 확률:\".format(topn), top_10_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca80d2-26be-47e1-9523-ffb2f4ba88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ccd, num_bzc, num_grup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "504666f3-8654-4fba-8b07-ff6d651f4045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 91, 750, 310],\n",
       " [2, 91, 750, 422],\n",
       " [2, 91, 750, 407],\n",
       " [2, 91, 750, 31],\n",
       " [2, 91, 750, 10],\n",
       " [2, 91, 750, 6],\n",
       " [2, 91, 750, 387],\n",
       " [2, 91, 750, 410],\n",
       " [2, 91, 750, 402],\n",
       " [2, 91, 750, 314],\n",
       " [2, 91, 750, 240],\n",
       " [2, 91, 750, 35],\n",
       " [2, 91, 750, 9],\n",
       " [2, 89, 810, 0],\n",
       " [2, 89, 810, 444],\n",
       " [2, 89, 810, 387],\n",
       " [2, 89, 810, 10],\n",
       " [2, 89, 810, 329],\n",
       " [2, 89, 810, 16],\n",
       " [2, 89, 810, 2278],\n",
       " [2, 89, 810, 402],\n",
       " [2, 89, 810, 390],\n",
       " [2, 89, 810, 364],\n",
       " [2, 89, 810, 332],\n",
       " [2, 89, 810, 313],\n",
       " [2, 89, 810, 385],\n",
       " [1, 88, 812, 410],\n",
       " [1, 88, 812, 5],\n",
       " [1, 88, 812, 2278],\n",
       " [1, 88, 812, 4],\n",
       " [1, 88, 812, 15],\n",
       " [1, 88, 812, 402],\n",
       " [1, 88, 812, 53],\n",
       " [1, 88, 812, 6],\n",
       " [1, 88, 812, 387],\n",
       " [1, 88, 812, 386],\n",
       " [1, 88, 812, 305],\n",
       " [1, 88, 812, 444],\n",
       " [2, 100, 715, 328],\n",
       " [2, 100, 715, 23],\n",
       " [2, 100, 715, 5],\n",
       " [2, 100, 715, 337],\n",
       " [2, 100, 715, 402],\n",
       " [2, 100, 715, 425],\n",
       " [2, 100, 715, 7869],\n",
       " [2, 100, 715, 7871],\n",
       " [2, 100, 715, 386],\n",
       " [2, 100, 715, 9],\n",
       " [2, 100, 715, 240],\n",
       " [2, 100, 715, 16587],\n",
       " [2, 100, 715, 438],\n",
       " [2, 100, 715, 410],\n",
       " [2, 100, 715, 390],\n",
       " [2, 100, 684, 428],\n",
       " [2, 100, 684, 422],\n",
       " [2, 100, 684, 387],\n",
       " [2, 100, 684, 7869],\n",
       " [2, 100, 684, 257],\n",
       " [2, 100, 684, 425],\n",
       " [2, 100, 684, 214],\n",
       " [2, 100, 684, 26],\n",
       " [2, 100, 684, 23],\n",
       " [2, 100, 684, 438],\n",
       " [2, 100, 684, 7871],\n",
       " [2, 100, 684, 9],\n",
       " [2, 100, 684, 7870],\n",
       " [2, 100, 684, 385],\n",
       " [2, 100, 684, 328],\n",
       " [2, 100, 787, 402],\n",
       " [2, 100, 787, 324],\n",
       " [2, 100, 787, 337],\n",
       " [2, 100, 787, 7869],\n",
       " [2, 100, 787, 103],\n",
       " [2, 100, 787, 9],\n",
       " [2, 100, 787, 23],\n",
       " [2, 100, 787, 328],\n",
       " [2, 100, 787, 16587],\n",
       " [2, 100, 787, 5],\n",
       " [2, 100, 787, 8],\n",
       " [2, 100, 787, 7871],\n",
       " [2, 100, 787, 410],\n",
       " [2, 100, 787, 386],\n",
       " [2, 100, 787, 425],\n",
       " [2, 101, 693, 9],\n",
       " [2, 101, 693, 16587],\n",
       " [2, 101, 693, 410],\n",
       " [2, 101, 693, 387],\n",
       " [2, 101, 693, 309],\n",
       " [2, 101, 693, 31],\n",
       " [2, 101, 693, 7871],\n",
       " [2, 101, 693, 390],\n",
       " [2, 101, 693, 407],\n",
       " [2, 101, 693, 386],\n",
       " [2, 101, 693, 7870],\n",
       " [2, 101, 693, 438],\n",
       " [2, 101, 693, 422],\n",
       " [2, 101, 693, 328],\n",
       " [2, 101, 693, 4],\n",
       " [2, 101, 693, 402],\n",
       " [2, 101, 693, 23],\n",
       " [2, 101, 693, 240],\n",
       " [2, 101, 693, 10],\n",
       " [2, 101, 693, 7869],\n",
       " [2, 293, 895, 449],\n",
       " [2, 293, 895, 447],\n",
       " [2, 293, 895, 7870],\n",
       " [2, 293, 895, 444],\n",
       " [2, 293, 895, 123],\n",
       " [2, 293, 895, 24],\n",
       " [2, 293, 895, 7871],\n",
       " [2, 293, 895, 18],\n",
       " [2, 293, 895, 10],\n",
       " [2, 293, 895, 16587],\n",
       " [2, 293, 895, 7869],\n",
       " [2, 293, 895, 402],\n",
       " [2, 293, 895, 328],\n",
       " [2, 293, 895, 304],\n",
       " [2, 293, 895, 240],\n",
       " [2, 293, 895, 427],\n",
       " [2, 101, 684, 7871],\n",
       " [2, 101, 684, 31],\n",
       " [2, 101, 684, 240],\n",
       " [2, 101, 684, 3],\n",
       " [2, 101, 684, 7869],\n",
       " [2, 101, 684, 422],\n",
       " [2, 101, 684, 7870],\n",
       " [2, 101, 684, 642],\n",
       " [2, 101, 684, 438],\n",
       " [2, 101, 684, 386],\n",
       " [2, 101, 684, 444],\n",
       " [2, 101, 684, 387],\n",
       " [2, 101, 684, 328],\n",
       " [2, 101, 684, 257],\n",
       " [2, 101, 684, 8],\n",
       " [2, 101, 684, 385],\n",
       " [2, 101, 684, 5],\n",
       " [2, 2, 693, 329],\n",
       " [2, 2, 693, 438],\n",
       " [2, 2, 693, 7869],\n",
       " [2, 2, 693, 444],\n",
       " [2, 2, 693, 8],\n",
       " [2, 2, 693, 402],\n",
       " [2, 2, 693, 49],\n",
       " [2, 2, 693, 337],\n",
       " [2, 2, 693, 10],\n",
       " [2, 2, 693, 7871],\n",
       " [2, 2, 693, 7870],\n",
       " [2, 2, 693, 386],\n",
       " [1, 100, 40, 410],\n",
       " [1, 100, 40, 7871],\n",
       " [1, 100, 40, 308],\n",
       " [1, 100, 40, 386],\n",
       " [1, 100, 40, 9],\n",
       " [1, 100, 40, 23],\n",
       " [1, 100, 40, 10],\n",
       " [1, 100, 40, 451],\n",
       " [1, 100, 40, 402],\n",
       " [1, 100, 40, 7869],\n",
       " [1, 100, 40, 8],\n",
       " [1, 100, 40, 16587],\n",
       " [1, 100, 40, 31],\n",
       " [1, 100, 40, 390],\n",
       " [1, 100, 40, 323],\n",
       " [1, 100, 40, 7870],\n",
       " [1, 100, 40, 328],\n",
       " [1, 100, 40, 438],\n",
       " [1, 100, 48, 31],\n",
       " [1, 100, 48, 9],\n",
       " [1, 100, 48, 402],\n",
       " [1, 100, 48, 385],\n",
       " [1, 100, 48, 7871],\n",
       " [1, 100, 48, 424],\n",
       " [1, 100, 48, 7869],\n",
       " [1, 100, 48, 386],\n",
       " [1, 100, 48, 5],\n",
       " [1, 100, 48, 329],\n",
       " [1, 152, 814, 457],\n",
       " [1, 152, 814, 5],\n",
       " [1, 152, 814, 329],\n",
       " [1, 152, 814, 429],\n",
       " [1, 152, 814, 410],\n",
       " [1, 152, 814, 402],\n",
       " [1, 152, 814, 6719],\n",
       " [1, 152, 814, 328],\n",
       " [1, 152, 814, 642],\n",
       " [1, 152, 814, 50],\n",
       " [1, 152, 814, 257],\n",
       " [1, 152, 814, 16],\n",
       " [1, 152, 814, 444],\n",
       " [1, 152, 814, 325],\n",
       " [1, 152, 814, 58],\n",
       " [1, 152, 814, 55],\n",
       " [1, 152, 814, 307],\n",
       " [2, 90, 535, 240],\n",
       " [2, 90, 535, 315],\n",
       " [2, 90, 535, 10],\n",
       " [2, 90, 535, 402],\n",
       " [2, 90, 535, 55],\n",
       " [2, 90, 535, 6719],\n",
       " [2, 90, 535, 422],\n",
       " [2, 90, 535, 457],\n",
       " [2, 90, 535, 16],\n",
       " [2, 90, 535, 327],\n",
       " [2, 90, 535, 444],\n",
       " [2, 90, 801, 58],\n",
       " [2, 90, 801, 315],\n",
       " [2, 90, 801, 306],\n",
       " [2, 90, 801, 429],\n",
       " [2, 90, 801, 402],\n",
       " [2, 90, 801, 31],\n",
       " [2, 90, 801, 457],\n",
       " [2, 90, 801, 411],\n",
       " [2, 90, 801, 444],\n",
       " [2, 90, 801, 6719],\n",
       " [2, 90, 801, 642],\n",
       " [2, 90, 801, 328],\n",
       " [1, 90, 724, 6719],\n",
       " [1, 90, 724, 457],\n",
       " [1, 90, 724, 402],\n",
       " [1, 90, 724, 29],\n",
       " [1, 90, 724, 445],\n",
       " [1, 233, 38, 329],\n",
       " [1, 233, 38, 422],\n",
       " [1, 233, 38, 327],\n",
       " [1, 233, 38, 1],\n",
       " [1, 233, 38, 257],\n",
       " [1, 233, 38, 41],\n",
       " [1, 233, 38, 255],\n",
       " [1, 233, 38, 438],\n",
       " [1, 233, 38, 459],\n",
       " [1, 233, 38, 6],\n",
       " [1, 233, 38, 221],\n",
       " [1, 233, 38, 51],\n",
       " [1, 232, 684, 122],\n",
       " [1, 232, 684, 240],\n",
       " [1, 232, 684, 438],\n",
       " [1, 232, 684, 329],\n",
       " [1, 232, 684, 410],\n",
       " [1, 232, 684, 10],\n",
       " [1, 232, 684, 459],\n",
       " [1, 232, 684, 6],\n",
       " [1, 232, 684, 4],\n",
       " [1, 232, 684, 428],\n",
       " [1, 232, 684, 51],\n",
       " [2, 233, 733, 444],\n",
       " [2, 233, 733, 26],\n",
       " [2, 233, 733, 25],\n",
       " [2, 233, 733, 8],\n",
       " [2, 233, 733, 255],\n",
       " [2, 233, 733, 459],\n",
       " [2, 233, 733, 438],\n",
       " [2, 233, 733, 257],\n",
       " [2, 233, 39, 8],\n",
       " [2, 233, 39, 122],\n",
       " [2, 233, 39, 459],\n",
       " [2, 233, 39, 428],\n",
       " [2, 233, 39, 221],\n",
       " [2, 233, 39, 0],\n",
       " [2, 233, 39, 6],\n",
       " [2, 233, 39, 49],\n",
       " [2, 233, 39, 422],\n",
       " [2, 233, 39, 400],\n",
       " [2, 233, 39, 26],\n",
       " [2, 233, 39, 438],\n",
       " [2, 233, 39, 449],\n",
       " [2, 233, 39, 411],\n",
       " [1, 232, 684, 400],\n",
       " [1, 232, 684, 51],\n",
       " [1, 232, 684, 221],\n",
       " [1, 232, 684, 6],\n",
       " [1, 232, 684, 428],\n",
       " [1, 232, 623, 410],\n",
       " [1, 232, 623, 147],\n",
       " [1, 232, 623, 444],\n",
       " [1, 232, 623, 428],\n",
       " [1, 232, 623, 15],\n",
       " [1, 232, 623, 329],\n",
       " [1, 232, 623, 122],\n",
       " [1, 232, 623, 47],\n",
       " [1, 232, 623, 459],\n",
       " [1, 232, 623, 425],\n",
       " [1, 232, 623, 421],\n",
       " [1, 233, 2, 255],\n",
       " [1, 233, 2, 240],\n",
       " [1, 233, 2, 23],\n",
       " [1, 233, 2, 323],\n",
       " [1, 233, 2, 444],\n",
       " [1, 233, 2, 459],\n",
       " [1, 233, 2, 5],\n",
       " [1, 233, 2, 400],\n",
       " [1, 233, 2, 3],\n",
       " [1, 233, 2, 324],\n",
       " [1, 233, 2, 221],\n",
       " [1, 233, 2, 4],\n",
       " [1, 233, 2, 147],\n",
       " [2, 235, 153, 3],\n",
       " [2, 235, 153, 642],\n",
       " [2, 235, 153, 428],\n",
       " [2, 235, 153, 122],\n",
       " [2, 235, 153, 323],\n",
       " [2, 235, 153, 240],\n",
       " [2, 235, 153, 411],\n",
       " [2, 235, 153, 221],\n",
       " [2, 235, 153, 51],\n",
       " [2, 235, 153, 147],\n",
       " [2, 235, 153, 8],\n",
       " [2, 235, 153, 459],\n",
       " [2, 235, 153, 425],\n",
       " [2, 235, 153, 214],\n",
       " [2, 235, 153, 422],\n",
       " [2, 235, 153, 438],\n",
       " [1, 235, 1, 459],\n",
       " [1, 235, 1, 438],\n",
       " [1, 235, 1, 410],\n",
       " [1, 235, 1, 122],\n",
       " [1, 235, 1, 411],\n",
       " [1, 235, 1, 51],\n",
       " [1, 235, 1, 8],\n",
       " [2, 234, 751, 438],\n",
       " [2, 234, 751, 240],\n",
       " [2, 234, 751, 31],\n",
       " [2, 234, 751, 308],\n",
       " [2, 234, 751, 411],\n",
       " [2, 234, 751, 255],\n",
       " [2, 234, 751, 51],\n",
       " [2, 234, 751, 147],\n",
       " [2, 234, 751, 8],\n",
       " [2, 234, 751, 459],\n",
       " [2, 234, 751, 23],\n",
       " [2, 234, 751, 428],\n",
       " [2, 234, 751, 5],\n",
       " [2, 235, 465, 444],\n",
       " [2, 235, 465, 428],\n",
       " [2, 235, 465, 31],\n",
       " [2, 235, 465, 8],\n",
       " [2, 235, 465, 51],\n",
       " [2, 235, 465, 147],\n",
       " [2, 235, 465, 400],\n",
       " [2, 235, 465, 308],\n",
       " [2, 235, 465, 240],\n",
       " [2, 235, 465, 122],\n",
       " [2, 235, 465, 642],\n",
       " [2, 235, 465, 459],\n",
       " [2, 235, 465, 424],\n",
       " [2, 235, 465, 438],\n",
       " [1, 234, 153, 122],\n",
       " [1, 234, 153, 8],\n",
       " [1, 235, 806, 428],\n",
       " [1, 235, 806, 240],\n",
       " [1, 235, 806, 214],\n",
       " [1, 235, 806, 122],\n",
       " [1, 235, 806, 10],\n",
       " [1, 235, 806, 459],\n",
       " [1, 235, 806, 438],\n",
       " [1, 235, 806, 400],\n",
       " [1, 235, 806, 329],\n",
       " [1, 235, 806, 147],\n",
       " [1, 235, 806, 51],\n",
       " [1, 235, 806, 35],\n",
       " [1, 235, 806, 8],\n",
       " [1, 257, 644, 429],\n",
       " [1, 257, 644, 410],\n",
       " [1, 257, 644, 308],\n",
       " [1, 257, 644, 31],\n",
       " [1, 257, 644, 8],\n",
       " [1, 257, 644, 23],\n",
       " [1, 257, 644, 4042],\n",
       " [1, 257, 644, 240],\n",
       " [1, 257, 644, 328],\n",
       " [1, 257, 644, 447],\n",
       " [1, 257, 644, 4019],\n",
       " [1, 257, 644, 4033],\n",
       " [1, 257, 644, 323],\n",
       " [1, 257, 644, 4020],\n",
       " [1, 257, 644, 4013],\n",
       " [1, 257, 644, 3999],\n",
       " [1, 257, 644, 444],\n",
       " [1, 257, 143, 3999],\n",
       " [1, 257, 143, 240],\n",
       " [1, 257, 143, 429],\n",
       " [1, 257, 143, 23],\n",
       " [1, 257, 143, 9],\n",
       " [1, 257, 143, 444],\n",
       " [1, 257, 143, 328],\n",
       " [1, 257, 143, 4042],\n",
       " [1, 257, 143, 4019],\n",
       " [1, 257, 143, 324],\n",
       " [1, 257, 143, 3],\n",
       " [1, 257, 143, 422],\n",
       " [1, 257, 143, 103],\n",
       " [1, 257, 143, 4013],\n",
       " [1, 257, 143, 323],\n",
       " [1, 257, 143, 4033],\n",
       " [1, 257, 143, 4020],\n",
       " [2, 258, 642, 324],\n",
       " [2, 258, 642, 240],\n",
       " [2, 258, 642, 429],\n",
       " [2, 258, 642, 4019],\n",
       " [2, 258, 642, 311],\n",
       " [2, 258, 642, 411],\n",
       " [2, 258, 642, 23],\n",
       " [2, 258, 642, 9],\n",
       " [2, 258, 642, 3999],\n",
       " [2, 258, 642, 444],\n",
       " [2, 258, 642, 425],\n",
       " [2, 258, 642, 328],\n",
       " [2, 258, 642, 323],\n",
       " [2, 258, 642, 420],\n",
       " [2, 258, 642, 4013],\n",
       " [2, 258, 642, 4042],\n",
       " [2, 258, 642, 4033],\n",
       " [2, 258, 642, 4020],\n",
       " [2, 258, 551, 328],\n",
       " [2, 258, 551, 4033],\n",
       " [2, 258, 551, 4013],\n",
       " [2, 258, 551, 444],\n",
       " [2, 258, 551, 4019],\n",
       " [2, 258, 551, 23],\n",
       " [2, 258, 551, 429],\n",
       " [2, 258, 551, 308],\n",
       " [2, 258, 551, 4042],\n",
       " [2, 258, 551, 24],\n",
       " [2, 258, 551, 103],\n",
       " [2, 258, 551, 3999],\n",
       " [2, 258, 551, 4020],\n",
       " [2, 258, 551, 9],\n",
       " [2, 258, 551, 410],\n",
       " [2, 258, 551, 240],\n",
       " [2, 258, 551, 323],\n",
       " [2, 258, 638, 240],\n",
       " [2, 258, 638, 23],\n",
       " [2, 258, 638, 328],\n",
       " [2, 258, 638, 8],\n",
       " [2, 258, 638, 4042],\n",
       " [2, 258, 638, 323],\n",
       " [2, 258, 638, 4013],\n",
       " [2, 258, 638, 3999],\n",
       " [2, 258, 638, 4019],\n",
       " [2, 258, 638, 444],\n",
       " [2, 258, 638, 429],\n",
       " [2, 258, 638, 411],\n",
       " [2, 258, 638, 324],\n",
       " [2, 258, 638, 311],\n",
       " [2, 258, 638, 305],\n",
       " [2, 258, 638, 9],\n",
       " [2, 258, 638, 4033],\n",
       " [2, 258, 638, 4020],\n",
       " [1, 257, 651, 9],\n",
       " [1, 257, 651, 4033],\n",
       " [1, 257, 651, 4042],\n",
       " [1, 257, 651, 4019],\n",
       " [1, 257, 651, 3999],\n",
       " [1, 257, 651, 444],\n",
       " [1, 257, 651, 430],\n",
       " [1, 257, 651, 328],\n",
       " [1, 257, 651, 4013],\n",
       " [1, 257, 651, 33],\n",
       " [1, 257, 651, 4020],\n",
       " [2, 275, 677, 4348],\n",
       " [2, 275, 677, 4415],\n",
       " [2, 275, 677, 4405],\n",
       " [2, 275, 677, 4417],\n",
       " [2, 275, 677, 429],\n",
       " [2, 275, 677, 32],\n",
       " [2, 275, 677, 4326],\n",
       " [2, 275, 677, 4324],\n",
       " [2, 275, 677, 4349],\n",
       " [2, 275, 677, 4327],\n",
       " [2, 275, 677, 4406],\n",
       " [2, 275, 677, 4346],\n",
       " [2, 275, 677, 4345],\n",
       " [2, 275, 677, 4323],\n",
       " [2, 275, 677, 4320],\n",
       " [2, 275, 677, 4322],\n",
       " [2, 275, 677, 444],\n",
       " [2, 275, 677, 8],\n",
       " [2, 263, 888, 325],\n",
       " [2, 263, 888, 4527],\n",
       " [2, 263, 888, 308],\n",
       " [2, 263, 888, 240],\n",
       " [2, 263, 888, 23],\n",
       " [2, 263, 888, 4566],\n",
       " [2, 263, 888, 422],\n",
       " [2, 263, 888, 4521],\n",
       " [2, 263, 888, 4557],\n",
       " [2, 263, 888, 4511],\n",
       " [2, 263, 888, 4490],\n",
       " [2, 263, 888, 4524],\n",
       " [2, 263, 888, 4522],\n",
       " [2, 263, 888, 4523],\n",
       " [2, 263, 888, 4526],\n",
       " [2, 263, 888, 53],\n",
       " [2, 263, 888, 4525],\n",
       " [2, 263, 888, 4497],\n",
       " [2, 263, 888, 411],\n",
       " [2, 263, 888, 4528],\n",
       " [2, 263, 888, 4581],\n",
       " [2, 263, 888, 4561],\n",
       " [2, 263, 888, 4558],\n",
       " [2, 273, 876, 4611],\n",
       " [2, 273, 876, 429],\n",
       " [2, 273, 876, 363],\n",
       " [2, 273, 876, 444],\n",
       " [2, 273, 876, 297],\n",
       " [2, 273, 876, 31],\n",
       " [2, 273, 876, 4614],\n",
       " [2, 273, 876, 415],\n",
       " [2, 273, 876, 4612],\n",
       " [2, 273, 876, 424],\n",
       " [2, 273, 876, 350],\n",
       " [2, 273, 876, 300],\n",
       " [2, 273, 876, 4650],\n",
       " [1, 272, 649, 444],\n",
       " [1, 272, 649, 460],\n",
       " [1, 272, 649, 390],\n",
       " [1, 272, 649, 429],\n",
       " [1, 272, 649, 468],\n",
       " [1, 272, 649, 323],\n",
       " [1, 272, 649, 8],\n",
       " [1, 272, 649, 50],\n",
       " [1, 272, 649, 23],\n",
       " [1, 272, 649, 422],\n",
       " [1, 272, 649, 463],\n",
       " [1, 272, 649, 469],\n",
       " [1, 272, 649, 49],\n",
       " [1, 272, 649, 308],\n",
       " [1, 272, 649, 324],\n",
       " [1, 272, 649, 470],\n",
       " [2, 272, 768, 5],\n",
       " [2, 272, 768, 328],\n",
       " [2, 272, 768, 460],\n",
       " [2, 272, 768, 323],\n",
       " [2, 272, 768, 411],\n",
       " [2, 272, 768, 31],\n",
       " [2, 272, 768, 240],\n",
       " [2, 272, 768, 468],\n",
       " [2, 272, 768, 429],\n",
       " [2, 272, 768, 8],\n",
       " [2, 272, 768, 324],\n",
       " [2, 272, 768, 9],\n",
       " [2, 272, 768, 469],\n",
       " [2, 272, 768, 444],\n",
       " [2, 272, 768, 463],\n",
       " [2, 272, 768, 470],\n",
       " [2, 272, 649, 470],\n",
       " [2, 272, 649, 469],\n",
       " [2, 272, 649, 463],\n",
       " [2, 272, 649, 429],\n",
       " [2, 272, 649, 0],\n",
       " [2, 272, 649, 468],\n",
       " [2, 272, 649, 460],\n",
       " [2, 272, 649, 49],\n",
       " [2, 272, 649, 328],\n",
       " [2, 272, 649, 422],\n",
       " [2, 272, 649, 308],\n",
       " [2, 272, 649, 324],\n",
       " [2, 272, 649, 50],\n",
       " [2, 272, 649, 642],\n",
       " [2, 272, 649, 5],\n",
       " [2, 272, 649, 444],\n",
       " [2, 272, 649, 642],\n",
       " [2, 272, 653, 5],\n",
       " [2, 272, 653, 468],\n",
       " [2, 272, 653, 429],\n",
       " [2, 272, 653, 324],\n",
       " [2, 272, 653, 41],\n",
       " [2, 272, 653, 31],\n",
       " [2, 272, 653, 460],\n",
       " [2, 272, 653, 445],\n",
       " [2, 272, 653, 53],\n",
       " [2, 272, 653, 314],\n",
       " [2, 272, 653, 318],\n",
       " [1, 122, 799, 26],\n",
       " [1, 122, 799, 411],\n",
       " [1, 122, 799, 410],\n",
       " [1, 122, 799, 96],\n",
       " [1, 122, 799, 327],\n",
       " [1, 122, 799, 394],\n",
       " [1, 122, 799, 95],\n",
       " [1, 122, 799, 10],\n",
       " [1, 122, 799, 18],\n",
       " [1, 122, 799, 326],\n",
       " [1, 122, 799, 31],\n",
       " [1, 122, 799, 240],\n",
       " [1, 122, 799, 66],\n",
       " [1, 122, 799, 8],\n",
       " [1, 122, 799, 5],\n",
       " [1, 122, 799, 319],\n",
       " [1, 122, 799, 97],\n",
       " [2, 122, 149, 328],\n",
       " [2, 122, 149, 41],\n",
       " [2, 122, 149, 31],\n",
       " [2, 122, 149, 8],\n",
       " [2, 122, 149, 10],\n",
       " [2, 122, 149, 26],\n",
       " [2, 122, 149, 5],\n",
       " [2, 122, 149, 3260],\n",
       " [2, 122, 149, 308],\n",
       " [2, 122, 149, 66],\n",
       " [2, 122, 149, 22],\n",
       " [2, 122, 149, 240],\n",
       " [2, 122, 149, 314],\n",
       " [2, 122, 149, 642],\n",
       " [2, 122, 149, 95],\n",
       " [2, 122, 149, 394],\n",
       " [1, 122, 695, 29],\n",
       " [1, 122, 695, 96],\n",
       " [1, 122, 695, 5],\n",
       " [1, 122, 695, 26],\n",
       " [1, 122, 695, 41],\n",
       " [1, 122, 695, 66],\n",
       " [1, 122, 695, 329],\n",
       " [1, 122, 695, 240],\n",
       " [1, 122, 695, 308],\n",
       " [1, 122, 695, 307],\n",
       " [1, 122, 695, 97],\n",
       " [1, 122, 695, 394],\n",
       " [1, 122, 695, 444],\n",
       " [1, 122, 695, 2578],\n",
       " [2, 133, 824, 429],\n",
       " [2, 133, 824, 2696],\n",
       " [2, 133, 824, 2653],\n",
       " [2, 133, 824, 444],\n",
       " [2, 133, 824, 362],\n",
       " [2, 133, 824, 422],\n",
       " [2, 133, 824, 204],\n",
       " [2, 133, 824, 150],\n",
       " [2, 133, 824, 47],\n",
       " [2, 133, 824, 323],\n",
       " [2, 133, 824, 2694],\n",
       " [2, 133, 824, 206],\n",
       " [2, 133, 824, 2692],\n",
       " [2, 133, 824, 2693],\n",
       " [2, 133, 824, 151],\n",
       " [2, 133, 824, 151],\n",
       " [2, 133, 824, 150],\n",
       " [2, 133, 824, 2696],\n",
       " [2, 133, 824, 308],\n",
       " [2, 133, 824, 102],\n",
       " [2, 133, 824, 48],\n",
       " [2, 133, 824, 2693],\n",
       " [2, 133, 824, 2694],\n",
       " [2, 133, 824, 429],\n",
       " [2, 133, 824, 2692],\n",
       " [2, 133, 824, 329],\n",
       " [2, 133, 824, 323],\n",
       " [2, 133, 824, 47],\n",
       " [2, 133, 824, 2653],\n",
       " [2, 133, 824, 2731],\n",
       " [2, 133, 824, 2695],\n",
       " [2, 133, 824, 362],\n",
       " [2, 133, 824, 5],\n",
       " [2, 133, 824, 41],\n",
       " [2, 133, 824, 422],\n",
       " [2, 133, 824, 240],\n",
       " [2, 133, 824, 204],\n",
       " [2, 138, 715, 429],\n",
       " [2, 138, 715, 2733],\n",
       " [2, 138, 715, 257],\n",
       " [2, 138, 715, 444],\n",
       " [2, 138, 715, 204],\n",
       " [2, 138, 715, 150],\n",
       " [2, 138, 715, 99],\n",
       " [2, 138, 715, 422],\n",
       " [2, 138, 715, 2732],\n",
       " [2, 138, 715, 240],\n",
       " [2, 138, 715, 100],\n",
       " [2, 138, 715, 206],\n",
       " [2, 138, 831, 2732],\n",
       " [2, 138, 831, 99],\n",
       " [2, 138, 831, 204],\n",
       " [2, 138, 831, 150],\n",
       " [2, 138, 831, 103],\n",
       " [2, 138, 831, 422],\n",
       " [2, 138, 831, 53],\n",
       " [2, 138, 831, 429],\n",
       " [2, 138, 831, 2733],\n",
       " [2, 138, 831, 444],\n",
       " [2, 138, 831, 100],\n",
       " [2, 138, 831, 312],\n",
       " [2, 138, 831, 23],\n",
       " [2, 138, 831, 206],\n",
       " [2, 138, 831, 449],\n",
       " [2, 138, 831, 5],\n",
       " [2, 138, 831, 2735],\n",
       " [2, 138, 825, 362],\n",
       " [2, 138, 825, 2732],\n",
       " [2, 138, 825, 2696],\n",
       " [2, 138, 825, 366],\n",
       " [2, 138, 825, 2653],\n",
       " [2, 138, 825, 444],\n",
       " [2, 138, 825, 2698],\n",
       " [2, 138, 825, 430],\n",
       " [2, 138, 825, 103],\n",
       " [2, 138, 825, 99],\n",
       " [2, 138, 825, 51],\n",
       " [2, 138, 825, 240],\n",
       " [2, 138, 825, 203],\n",
       " [2, 138, 825, 8],\n",
       " [1, 138, 879, 2732],\n",
       " [1, 138, 879, 206],\n",
       " [1, 138, 879, 429],\n",
       " [1, 138, 879, 642],\n",
       " [1, 138, 879, 257],\n",
       " [1, 138, 879, 422],\n",
       " [1, 138, 879, 317],\n",
       " [1, 138, 879, 100],\n",
       " [1, 138, 879, 204],\n",
       " [1, 138, 879, 2733],\n",
       " [1, 138, 879, 2899],\n",
       " [1, 138, 879, 5],\n",
       " [1, 138, 879, 642],\n",
       " [1, 138, 879, 103],\n",
       " [1, 138, 879, 395],\n",
       " [1, 138, 879, 311],\n",
       " [1, 138, 879, 314],\n",
       " [2, 138, 825, 444],\n",
       " [2, 138, 825, 328],\n",
       " [2, 138, 825, 447],\n",
       " [2, 138, 825, 2733],\n",
       " [2, 138, 825, 2735],\n",
       " [2, 138, 825, 206],\n",
       " [2, 138, 825, 429],\n",
       " [2, 138, 825, 99],\n",
       " [2, 138, 825, 10],\n",
       " [2, 138, 825, 150],\n",
       " [2, 138, 825, 257],\n",
       " [2, 138, 825, 204],\n",
       " [2, 138, 825, 422],\n",
       " [2, 138, 825, 5],\n",
       " [2, 138, 825, 100],\n",
       " [2, 138, 825, 2732],\n",
       " [1, 132, 426, 2874],\n",
       " [1, 132, 426, 2900],\n",
       " [1, 132, 426, 422],\n",
       " [1, 132, 426, 445],\n",
       " [1, 132, 426, 240],\n",
       " [1, 132, 426, 204],\n",
       " [1, 132, 426, 2877],\n",
       " [1, 132, 426, 2918],\n",
       " [1, 132, 426, 2898],\n",
       " [1, 132, 426, 2958],\n",
       " [1, 132, 426, 109],\n",
       " [1, 132, 426, 2899],\n",
       " [1, 132, 426, 99],\n",
       " [1, 132, 426, 32],\n",
       " [1, 132, 426, 2920],\n",
       " [1, 132, 426, 2989],\n",
       " [1, 136, 799, 2918],\n",
       " [1, 136, 799, 2898],\n",
       " [1, 136, 799, 444],\n",
       " [1, 136, 799, 2958],\n",
       " [1, 136, 799, 2919],\n",
       " [1, 136, 799, 203],\n",
       " [1, 136, 799, 99],\n",
       " [1, 136, 799, 10],\n",
       " [1, 135, 543, 308],\n",
       " [1, 135, 543, 2918],\n",
       " [1, 135, 543, 26],\n",
       " [1, 135, 543, 203],\n",
       " [1, 135, 543, 150],\n",
       " [1, 135, 543, 2923],\n",
       " [1, 135, 543, 2958],\n",
       " [1, 135, 543, 3002],\n",
       " [1, 131, 825, 204],\n",
       " [1, 131, 825, 0],\n",
       " [1, 131, 825, 3003],\n",
       " [1, 131, 825, 444],\n",
       " [1, 131, 825, 32],\n",
       " [1, 131, 825, 99],\n",
       " [1, 131, 825, 149],\n",
       " [1, 131, 825, 422],\n",
       " [1, 131, 825, 206],\n",
       " [1, 131, 825, 438],\n",
       " [1, 131, 825, 303],\n",
       " [1, 131, 825, 332],\n",
       " [1, 131, 825, 352],\n",
       " [1, 131, 825, 328],\n",
       " [1, 131, 825, 3006],\n",
       " [1, 131, 825, 3005],\n",
       " [1, 123, 799, 3220],\n",
       " [1, 123, 799, 102],\n",
       " [1, 123, 799, 3205],\n",
       " [1, 123, 799, 3179],\n",
       " [1, 123, 799, 340],\n",
       " [1, 123, 799, 151],\n",
       " [1, 123, 799, 240],\n",
       " [1, 123, 799, 206],\n",
       " [1, 123, 799, 309],\n",
       " [1, 123, 799, 38],\n",
       " [1, 123, 799, 8],\n",
       " [1, 123, 799, 328],\n",
       " [1, 123, 799, 26],\n",
       " [1, 123, 799, 31],\n",
       " [1, 123, 799, 422],\n",
       " [1, 123, 799, 99],\n",
       " [1, 123, 799, 438],\n",
       " [2, 123, 775, 2608],\n",
       " [2, 123, 775, 102],\n",
       " [2, 123, 775, 410],\n",
       " [2, 123, 775, 436],\n",
       " [2, 123, 775, 5],\n",
       " [2, 123, 775, 3205],\n",
       " [2, 123, 775, 151],\n",
       " [2, 123, 775, 49],\n",
       " [2, 123, 775, 8],\n",
       " [2, 123, 775, 422],\n",
       " [2, 123, 775, 99],\n",
       " [2, 123, 775, 320],\n",
       " [2, 123, 775, 203],\n",
       " [2, 123, 775, 328],\n",
       " [2, 123, 775, 3179],\n",
       " [2, 123, 775, 50],\n",
       " [2, 123, 775, 3220],\n",
       " [1, 152, 799, 113],\n",
       " [1, 152, 799, 430],\n",
       " [1, 152, 799, 240],\n",
       " [1, 152, 799, 308],\n",
       " [1, 152, 799, 103],\n",
       " [1, 152, 799, 5],\n",
       " [1, 152, 799, 424],\n",
       " [1, 152, 799, 329],\n",
       " [1, 152, 799, 311],\n",
       " [1, 152, 799, 112],\n",
       " [1, 152, 799, 114],\n",
       " [1, 152, 799, 422],\n",
       " [1, 152, 799, 115],\n",
       " [1, 152, 799, 321],\n",
       " [2, 152, 715, 26],\n",
       " [2, 152, 715, 53],\n",
       " [2, 152, 715, 114],\n",
       " [2, 152, 715, 3287],\n",
       " [2, 152, 715, 431],\n",
       " [2, 152, 715, 323],\n",
       " [2, 152, 715, 422],\n",
       " [2, 152, 715, 31],\n",
       " [2, 152, 715, 13],\n",
       " [2, 152, 715, 395],\n",
       " [2, 152, 715, 425],\n",
       " [2, 152, 715, 113],\n",
       " [2, 152, 715, 112],\n",
       " [2, 152, 715, 4],\n",
       " [2, 152, 715, 444],\n",
       " [2, 152, 715, 328],\n",
       " [1, 153, 801, 8],\n",
       " [1, 153, 801, 10],\n",
       " [1, 153, 801, 328],\n",
       " [1, 153, 801, 414],\n",
       " [1, 153, 801, 321],\n",
       " [1, 153, 801, 115],\n",
       " [1, 153, 801, 31],\n",
       " [1, 153, 801, 112],\n",
       " [1, 153, 801, 5],\n",
       " [1, 153, 801, 411],\n",
       " [1, 153, 801, 240],\n",
       " [1, 153, 801, 113],\n",
       " [1, 153, 801, 395],\n",
       " [1, 153, 801, 316],\n",
       " [1, 153, 801, 118],\n",
       " [1, 153, 801, 444],\n",
       " [1, 152, 814, 395],\n",
       " [1, 152, 814, 332],\n",
       " [1, 152, 814, 411],\n",
       " [1, 152, 814, 112],\n",
       " [1, 152, 814, 113],\n",
       " [1, 152, 814, 10],\n",
       " [1, 152, 814, 410],\n",
       " [1, 152, 814, 5],\n",
       " [1, 152, 814, 9],\n",
       " [1, 152, 814, 308],\n",
       " [1, 152, 814, 214],\n",
       " [1, 152, 814, 117],\n",
       " [1, 152, 814, 114],\n",
       " [1, 152, 814, 328],\n",
       " [1, 152, 814, 6],\n",
       " [1, 152, 712, 319],\n",
       " [1, 152, 712, 313],\n",
       " [1, 152, 712, 13],\n",
       " [1, 152, 712, 113],\n",
       " [1, 152, 712, 444],\n",
       " [1, 152, 712, 118],\n",
       " [1, 152, 712, 311],\n",
       " [1, 152, 712, 257],\n",
       " [1, 152, 712, 447],\n",
       " [1, 152, 712, 5],\n",
       " [2, 150, 733, 445],\n",
       " [2, 150, 733, 103],\n",
       " [2, 150, 733, 26],\n",
       " [2, 150, 733, 9],\n",
       " [2, 150, 733, 118],\n",
       " [2, 150, 733, 53],\n",
       " [2, 150, 733, 395],\n",
       " [2, 150, 733, 422],\n",
       " [2, 150, 733, 313],\n",
       " [2, 150, 733, 112],\n",
       " [2, 150, 733, 5],\n",
       " [2, 150, 733, 117],\n",
       " [2, 150, 733, 324],\n",
       " [2, 150, 733, 308],\n",
       " [1, 150, 72, 312],\n",
       " [1, 150, 72, 117],\n",
       " [1, 150, 72, 324],\n",
       " [1, 150, 72, 114],\n",
       " [1, 150, 72, 53],\n",
       " [1, 150, 72, 18],\n",
       " [1, 150, 72, 5],\n",
       " [1, 150, 72, 112],\n",
       " [1, 150, 72, 395],\n",
       " [1, 150, 72, 398],\n",
       " [1, 150, 72, 427],\n",
       " [1, 150, 72, 410],\n",
       " [1, 150, 72, 240],\n",
       " [1, 150, 72, 257],\n",
       " [1, 149, 654, 9],\n",
       " [1, 149, 654, 41],\n",
       " [1, 149, 654, 329],\n",
       " [1, 149, 654, 312],\n",
       " [1, 149, 654, 118],\n",
       " [1, 149, 654, 395],\n",
       " [1, 149, 654, 328],\n",
       " [1, 149, 654, 319],\n",
       " [1, 149, 654, 410],\n",
       " [1, 149, 654, 431],\n",
       " [1, 149, 654, 240],\n",
       " [1, 149, 654, 324],\n",
       " [1, 149, 654, 112],\n",
       " [1, 149, 654, 425],\n",
       " [1, 149, 654, 116],\n",
       " [1, 150, 876, 305],\n",
       " [1, 150, 876, 320],\n",
       " [1, 150, 876, 116],\n",
       " [1, 150, 876, 444],\n",
       " [1, 150, 876, 240],\n",
       " [1, 150, 876, 445],\n",
       " [1, 150, 876, 114],\n",
       " [1, 150, 876, 390],\n",
       " [1, 150, 876, 9],\n",
       " [1, 150, 876, 310],\n",
       " [2, 149, 384, 5],\n",
       " [2, 149, 384, 0],\n",
       " [2, 149, 384, 113],\n",
       " [2, 149, 384, 312],\n",
       " [2, 149, 384, 310],\n",
       " [2, 149, 384, 395],\n",
       " [2, 149, 384, 424],\n",
       " [2, 149, 384, 4386],\n",
       " [2, 149, 384, 642],\n",
       " [2, 149, 384, 313],\n",
       " [2, 149, 384, 118],\n",
       " [2, 149, 384, 240],\n",
       " [2, 149, 384, 31],\n",
       " [2, 149, 384, 9],\n",
       " [2, 149, 384, 422],\n",
       " [2, 149, 384, 114],\n",
       " [2, 149, 384, 112],\n",
       " [2, 149, 384, 38],\n",
       " [2, 150, 812, 323],\n",
       " [2, 150, 812, 116],\n",
       " [2, 150, 812, 410],\n",
       " [2, 150, 812, 16],\n",
       " [2, 150, 812, 310],\n",
       " [2, 150, 812, 642],\n",
       " [2, 150, 812, 115],\n",
       " [2, 150, 812, 53],\n",
       " [2, 150, 812, 26],\n",
       " [2, 150, 812, 23],\n",
       " [1, 144, 668, 6],\n",
       " [1, 144, 668, 642],\n",
       " [1, 144, 668, 395],\n",
       " [1, 144, 668, 35],\n",
       " [1, 144, 668, 328],\n",
       " [1, 144, 668, 240],\n",
       " [1, 144, 668, 319],\n",
       " [1, 144, 668, 305],\n",
       " [1, 144, 668, 116],\n",
       " [1, 144, 668, 8],\n",
       " [1, 144, 668, 115],\n",
       " [1, 144, 668, 411],\n",
       " [1, 144, 668, 308],\n",
       " [1, 144, 668, 114],\n",
       " [1, 145, 216, 49],\n",
       " [1, 145, 216, 422],\n",
       " [1, 145, 216, 31],\n",
       " [1, 145, 216, 5],\n",
       " [1, 145, 216, 115],\n",
       " [1, 145, 216, 329],\n",
       " [1, 145, 216, 118],\n",
       " [1, 145, 216, 50],\n",
       " [1, 145, 216, 326],\n",
       " [1, 145, 216, 316],\n",
       " [1, 145, 216, 313],\n",
       " [1, 145, 216, 308],\n",
       " [2, 146, 317, 337],\n",
       " [2, 146, 317, 427],\n",
       " [2, 146, 317, 51],\n",
       " [2, 146, 317, 23],\n",
       " [2, 146, 317, 444],\n",
       " [2, 146, 317, 115],\n",
       " [2, 146, 317, 103],\n",
       " [2, 146, 317, 118],\n",
       " ...]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4e2672-b788-4a8a-863f-7ce8788065b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d909ba-4134-48af-8f48-fade6c788c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "for item in x_train:\n",
    "    key = tuple(item[:3])  # 2, 91, 750을 튜플로 만듭니다.\n",
    "    value = item[3]  # 나머지 값은 딕셔너리의 값으로 사용합니다.\n",
    "    \n",
    "    if key in train_dict:\n",
    "        train_dict[key].append(value)\n",
    "    else:\n",
    "        train_dict[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc411796-d7ce-4143-a719-2928511c8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for item in x_test:\n",
    "    key = tuple(item[:3])  # 2, 91, 750을 튜플로 만듭니다.\n",
    "    value = item[3]  # 나머지 값은 딕셔너리의 값으로 사용합니다.\n",
    "    \n",
    "    if key in result_dict:\n",
    "        result_dict[key].append(value)\n",
    "    else:\n",
    "        result_dict[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22166e96-3759-4436-8f98-1996099116e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[618, 6994, 12453, 509, 14047, 8935, 8942, 8956, 1732, 368, 8987, 8947, 642, 7004, 8963, 8940, 8987, 1076, 11162, 1408, 575, 8953, 8963, 8987, 6998, 8942, 1743, 8966, 1033, 8951, 8946, 1023, 8965, 7004, 8958, 575, 8939, 1016, 1076, 1019, 373, 8961, 8987, 8221, 8987, 380, 6994, 8951, 368, 367, 1668, 374, 8987, 1008, 373, 368, 8949, 8224, 8205, 8934, 7004, 8964, 8966, 1668, 998]\n"
     ]
    }
   ],
   "source": [
    "keys_list = list(result_dict.keys())\n",
    "for a in keys_list:\n",
    "    print(result_dict[a])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1123e2ae-c9fc-4dd9-a599-d2bc0402ece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [12:15<00:00, 13.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def precision_and_map(k_values):\n",
    "    precision_results = {k: [] for k in k_values}\n",
    "    map_results = {k: [] for k in k_values}\n",
    "    recall_results = {k: [] for k in k_values}\n",
    "    \n",
    "    for i in tqdm(keys_list, desc=\"Calculating Precision\", position=0, leave=True):\n",
    "        p = []\n",
    "        try:\n",
    "            b = result_dict[i]\n",
    "            c = train_dict[i]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        for j in range(num_grup):\n",
    "            p.append(list(i) + [j])  # Fix variable name from 'a' to 'i'\n",
    "        \n",
    "        p = torch.tensor(p).to(device)\n",
    "        pred = net(p).to(torch.int)  # Change to 'torch.int' for data type\n",
    "        values, sorted_indices = torch.sort(pred, descending=True)\n",
    "        \n",
    "        original_indices = [idx for idx in sorted_indices.tolist() if idx not in set(c)]\n",
    "        \n",
    "        for k in k_values:\n",
    "            exclusive_indices = original_indices[:k]  # Use the original indices here\n",
    "            # Precision 계산\n",
    "            intersection_count_k = len(set(b).intersection(set(exclusive_indices)))\n",
    "            precision_results[k].append(intersection_count_k / k)\n",
    "            # recall 계산 \n",
    "            recall_results[k].append(intersection_count_k / len(b))\n",
    "            # MAP 계산\n",
    "            precision_at_i = []\n",
    "            \n",
    "            for rank, idx in enumerate(exclusive_indices, start=1):\n",
    "                if idx in set(b):\n",
    "                    precision_at_i.append(sum([1 if r in set(b) else 0 for r in exclusive_indices[:rank]]) / rank)\n",
    "            \n",
    "            if precision_at_i:\n",
    "                map_results[k].append(sum(precision_at_i) / len(precision_at_i))\n",
    "            else:\n",
    "                map_results[k].append(0.0)\n",
    "    return precision_results, map_results, recall_results\n",
    "\n",
    "k_values = [10, 25, 50, 100]\n",
    "precision_results, map_results, recall_results = precision_and_map(k_values)\n",
    "\n",
    "# Access the results\n",
    "precision_result_10 = precision_results[10]\n",
    "precision_result_25 = precision_results[25]\n",
    "precision_result_50 = precision_results[50]\n",
    "precision_result_100 = precision_results[100]\n",
    "\n",
    "map_result_10 = map_results[10]\n",
    "map_result_25 = map_results[25]\n",
    "map_result_50 = map_results[50]\n",
    "map_result_100 = map_results[100]\n",
    "\n",
    "recall_result_10 = recall_results[10]\n",
    "recall_result_25 = recall_results[25]\n",
    "recall_result_50 = recall_results[50]\n",
    "recall_result_100 = recall_results[100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66302c52-ad8e-498e-bf13-d6ff8cc2635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 Mean: 0.18488541666666666\n",
      "Precision@25 Mean: 0.1467166666666667\n",
      "Precision@50 Mean: 0.11504166666666668\n",
      "Precision@100 Mean: 0.08438958333333334\n",
      "Recall@10 Mean: 0.09999097819272576\n",
      "Recall@25 Mean: 0.19769707530985323\n",
      "Recall@50 Mean: 0.3077995819361884\n",
      "Recall@100 Mean: 0.44838159766161007\n",
      "MAP@10 Mean: 0.3486109190956475\n",
      "MAP@25 Mean: 0.2990134906078117\n",
      "MAP@50 Mean: 0.2533854720277903\n",
      "MAP@100 Mean: 0.21371601340008298\n"
     ]
    }
   ],
   "source": [
    "precision_10_mean = np.mean(precision_result_10)\n",
    "precision_25_mean = np.mean(precision_result_25)\n",
    "precision_50_mean = np.mean(precision_result_50)\n",
    "precision_100_mean = np.mean(precision_result_100)\n",
    "\n",
    "recall_10_mean = np.mean(recall_result_10)\n",
    "recall_25_mean = np.mean(recall_result_25)\n",
    "recall_50_mean = np.mean(recall_result_50)\n",
    "recall_100_mean = np.mean(recall_result_100)\n",
    "\n",
    "map_10_mean = np.mean(map_result_10)\n",
    "map_25_mean = np.mean(map_result_25)\n",
    "map_50_mean = np.mean(map_result_50)\n",
    "map_100_mean = np.mean(map_result_100)\n",
    "\n",
    "# 평균 출력\n",
    "print(\"Precision@10 Mean:\", precision_10_mean)\n",
    "print(\"Precision@25 Mean:\", precision_25_mean)\n",
    "print(\"Precision@50 Mean:\", precision_50_mean)\n",
    "print(\"Precision@100 Mean:\", precision_100_mean)\n",
    "\n",
    "print(\"Recall@10 Mean:\", recall_10_mean)\n",
    "print(\"Recall@25 Mean:\", recall_25_mean)\n",
    "print(\"Recall@50 Mean:\", recall_50_mean)\n",
    "print(\"Recall@100 Mean:\", recall_100_mean)\n",
    "\n",
    "print(\"MAP@10 Mean:\", map_10_mean)\n",
    "print(\"MAP@25 Mean:\", map_25_mean)\n",
    "print(\"MAP@50 Mean:\", map_50_mean)\n",
    "print(\"MAP@100 Mean:\", map_100_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7097045-3119-415a-8acd-328b1ff4d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def calculate_ap(gt, pred, k):\n",
    "    \"\"\"\n",
    "    단일 클래스에 대한 평균 정밀도 (AP)를 계산합니다.\n",
    "    \"\"\"\n",
    "    precision_at_k = 0.0\n",
    "    true_positives = 0\n",
    "\n",
    "    for i in range(k):\n",
    "        if pred[i] in gt:\n",
    "            true_positives += 1\n",
    "            precision_at_k += true_positives / (i + 1)\n",
    "\n",
    "    if not gt:\n",
    "        return 0.0\n",
    "\n",
    "    return precision_at_k / len(gt)\n",
    "\n",
    "def mean_average_precision(k):\n",
    "    result = []\n",
    "\n",
    "    for i in tqdm(keys_list, desc=\"mAP 계산 중\", position=0, leave=True):\n",
    "        try:\n",
    "            b = result_dict[i]\n",
    "            c = train_dict[i]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        p = []\n",
    "        for j in range(num_grup):\n",
    "            p.append(list(i) + [j])\n",
    "        p = torch.tensor(p).to(device)\n",
    "        pred = net(p).to(torch.int)\n",
    "        values, sorted_indices = torch.sort(pred, descending=True)\n",
    "\n",
    "        exclusive_indices = [idx for idx in sorted_indices.tolist() if idx not in set(c)] \n",
    "        exclusive_indices = exclusive_indices[:k]\n",
    "\n",
    "        ap = calculate_ap(b, exclusive_indices, k)\n",
    "        result.append(ap)\n",
    "\n",
    "    mean_ap = sum(result) / len(result) if result else 0.0\n",
    "    return mean_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "133db5c7-fef1-4e9f-a0e7-be92ffc9f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP 계산 중: 100%|█████████████████████████████████████████████████████████████████| 9600/9600 [06:04<00:00, 26.36it/s]\n",
      "mAP 계산 중: 100%|█████████████████████████████████████████████████████████████████| 9600/9600 [06:02<00:00, 26.48it/s]\n",
      "mAP 계산 중: 100%|█████████████████████████████████████████████████████████████████| 9600/9600 [06:05<00:00, 26.23it/s]\n",
      "mAP 계산 중: 100%|█████████████████████████████████████████████████████████████████| 9600/9600 [10:08<00:00, 15.78it/s]\n"
     ]
    }
   ],
   "source": [
    "map_10 = mean_average_precision(10)\n",
    "map_25 = mean_average_precision(25)\n",
    "map_50 = mean_average_precision(50)\n",
    "map_100 = mean_average_precision(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31570e20-0bf0-472d-9341-1510fe710676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05175221105177012\n",
      "0.0752485485405752\n",
      "0.09267475182604294\n",
      "0.10793466183742993\n"
     ]
    }
   ],
   "source": [
    "print(map_10)\n",
    "print(map_25)\n",
    "print(map_50)\n",
    "print(map_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3b7fd682-5318-428d-ab89-f0d6abf74ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.7, 0.0, 0.2, 0.2, 0.3, 0.2, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "# def precision(k)\n",
    "#     result = []\n",
    "#     for i in keys_list:  # Iterate only the first 5 elements of keys_list\n",
    "#         p = []\n",
    "#         try:\n",
    "#             b = result_dict[i]\n",
    "#             c = train_dict[i]\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "#         for j in range(num_grup):\n",
    "#             p.append(list(i) + [j])  # Fix variable name from 'a' to 'i'\n",
    "        \n",
    "#         p = torch.tensor(p).to(device)\n",
    "#         pred = net(p).to(torch.int)  # Change to 'torch.int' for data type\n",
    "#         values, sorted_indices = torch.sort(pred, descending=True)\n",
    "        \n",
    "#         exclusive_indices = [idx for idx in sorted_indices.tolist() if idx not in set(c)]\n",
    "#         exclusive_indices = exclusive_indices[:k]\n",
    "        \n",
    "#         intersection_count = len(set(b).intersection(set(exclusive_indices)))\n",
    "#         result.append(intersection_count / k)\n",
    "    \n",
    "#     return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5acd4ea5-2b4f-463e-bdb9-fc119f191de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def precision(k):\n",
    "    result = []\n",
    "    for i in tqdm(keys_list, desc=\"Calculating Precision\", position=0, leave=True):  # tqdm setup\n",
    "        p = []\n",
    "        try:\n",
    "            b = result_dict[i]\n",
    "            c = train_dict[i]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        for j in range(num_grup):\n",
    "            p.append(list(i) + [j])  # Fix variable name from 'a' to 'i'\n",
    "        \n",
    "        p = torch.tensor(p).to(device)\n",
    "        pred = net(p).to(torch.int)  # Change to 'torch.int' for data type\n",
    "        values, sorted_indices = torch.sort(pred, descending=True)\n",
    "        \n",
    "        exclusive_indices = [idx for idx in sorted_indices.tolist() if idx not in set(c)]\n",
    "        exclusive_indices = exclusive_indices[:k]\n",
    "        \n",
    "        intersection_count = len(set(b).intersection(set(exclusive_indices)))\n",
    "        result.append(intersection_count / k)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da2afe65-5e78-4c69-a492-81a7982ac08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [12:16<00:00, 13.03it/s]\n",
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [12:15<00:00, 13.06it/s]\n",
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [12:16<00:00, 13.03it/s]\n",
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [11:57<00:00, 13.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "a_10 = precision(10)\n",
    "a_25 = precision(25)\n",
    "a_50 = precision(50)\n",
    "a_100 = precision(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5844145-2a87-4ae5-940a-a4f5102a4376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18488541666666666\n",
      "0.1467166666666667\n",
      "0.11504166666666668\n",
      "0.08438958333333334\n"
     ]
    }
   ],
   "source": [
    "print(np.array(a_10).mean())\n",
    "print(np.array(a_25).mean())\n",
    "print(np.array(a_50).mean())\n",
    "print(np.array(a_100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "414235f9-289c-492b-b89e-8225b546c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def Recall(k):\n",
    "    result = []\n",
    "    for i in tqdm(keys_list, desc=\"Calculating Precision\", position=0, leave=True):  # tqdm setup\n",
    "        p = []\n",
    "        try:\n",
    "            b = result_dict[i]\n",
    "            c = train_dict[i]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        for j in range(num_grup):\n",
    "            p.append(list(i) + [j])  # Fix variable name from 'a' to 'i'\n",
    "        \n",
    "        p = torch.tensor(p).to(device)\n",
    "        pred = net(p).to(torch.int)  # Change to 'torch.int' for data type\n",
    "        values, sorted_indices = torch.sort(pred, descending=True)\n",
    "        \n",
    "        exclusive_indices = [idx for idx in sorted_indices.tolist() if idx not in set(c)]\n",
    "        exclusive_indices = exclusive_indices[:k]\n",
    "        \n",
    "        intersection_count = len(set(b).intersection(set(exclusive_indices)))\n",
    "        result.append(intersection_count / len(set(b)))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8450946-6053-4bde-919c-c7a32bc5e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [06:53<00:00, 23.24it/s]\n",
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [06:53<00:00, 23.19it/s]\n",
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [06:53<00:00, 23.24it/s]\n",
      "Calculating Precision: 100%|███████████████████████████████████████████████████████| 9600/9600 [06:53<00:00, 23.22it/s]\n"
     ]
    }
   ],
   "source": [
    "b_10 = Recall(10)\n",
    "b_25 = Recall(25)\n",
    "b_50 = Recall(50)\n",
    "b_100 = Recall(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7026d58-588a-48d3-b29a-f2070093a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1034699039873153\n",
      "0.20444689216100628\n",
      "0.3183467383520758\n",
      "0.46379674706775015\n"
     ]
    }
   ],
   "source": [
    "print(np.array(b_10).mean())\n",
    "print(np.array(b_25).mean())\n",
    "print(np.array(b_50).mean())\n",
    "print(np.array(b_100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec66ec-e8f3-45bc-b53a-08092922251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08200eb-d409-4660-a215-c37a09fc7f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_3.9",
   "language": "python",
   "name": "gnn_3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
